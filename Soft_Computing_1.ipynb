{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwsn4MJD7yKZyIGj6Z1JUl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smrutipunto/Soft-Computing/blob/main/Soft_Computing_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "vL0Y2iWJ7ft4",
        "outputId": "dedeef4b-4cce-4297-c3af-c66fe103d99d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'for' statement on line 21 (<ipython-input-9-3f5436668914>, line 22)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-3f5436668914>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    if (x1[i]*w1[i] + x2[i]*w2[i]) >= t:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 21\n"
          ]
        }
      ],
      "source": [
        "#Write a program to implement logical gates AND, OR and NOT, with McCulloch-Pitts.\n",
        "#For AND gate implementation:\n",
        "x1 = [0, 0, 1, 1]\n",
        "x2 = [0, 1, 0, 1]\n",
        "w1 = [1, 1, 1, 1]\n",
        "w2 = [1, 1, 1, 1]\n",
        "t = 2\n",
        "print(\"x1  x2  w1  w2  t  0\")\n",
        "for i in range(len(x1)):\n",
        "    if (x1[i]*w1[i] + x2[i]*w2[i]) >= t:\n",
        "        print(x1[i], '', x2[i], '', w1[i], '', w2[i], '', t, '', 1)\n",
        "else:\n",
        " print(x1[i], '', x2[i], '', w1[i], '', w2[i], '', t, '', 0)\n",
        " #For OR gate implementation:\n",
        "x1 = [0, 0, 1, 1]\n",
        "x2 = [0, 1, 0, 1]\n",
        "w1 = [1, 1, 1, 1]\n",
        "w2 = [1, 1, 1, 1]\n",
        "t = 1\n",
        "print(\"x1 x2 w1 w2 t 0\")\n",
        "for i in range(len(x1)):\n",
        " if (x1[i]*w1[i] + x2[i]*w2[i]) >= t:\n",
        "print(x1[i], '' , x2[i], '', w1[i], '‘ ’', w2[i], '‘ ’', t, '', 1)\n",
        "else:\n",
        "print(x1[i], '', x2[i], '', w1[i], '', w2[i], '', t, '', 0)\n",
        "#For not\n",
        "               x = [0, 1]\n",
        "w = [-1, -1]\n",
        "t = 0\n",
        "print(\"x w t 0\")\n",
        "for i in range(len(x)):\n",
        "if (x[i]*w[i]) >= t:\n",
        "print(x[i], '',w[i], '', t, '', 1)\n",
        "else:\n",
        "print(x[i], '',w[i], '', t, '', 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a program to implement Hebb’s learning rule.\n",
        "import numpy as np\n",
        "x1 = np.array ([1,1,1,-1,1,-1,1,1,1])\n",
        "x2 = np.array ([1,1,1,1,-1,1,1,1,1])\n",
        "b = 0\n",
        "y = np.array ([1,-1])\n",
        "wt_old = np.zeros ((9, ))\n",
        "wt_new = np.zeros ((9, ))\n",
        "wt_new = wt_new.astype(int)\n",
        "wt_old = wt_old.astype(int)\n",
        "bias = 0\n",
        "# FIRST INPUT\n",
        "print(\"First input with target = 1\")\n",
        "for i in range(0,9):\n",
        "  wt_old[i] = wt_old[i] + x1[i]*y[0]\n",
        "wt_new = wt_old\n",
        "b = b + y[0]\n",
        "print('Old weight = ', wt_old)\n",
        "print('Bias value = ', b)\n",
        "print('/n')\n",
        "# SECOND INPUT\n",
        "print('Second input with target = -1')\n",
        "for i in range(0,9):\n",
        "  wt_new[i] = wt_old[i] + x2[i]*y[1]\n",
        "b = b + y[1]\n",
        "print('New weight = ', wt_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9IhWgqS94_S",
        "outputId": "06ee77db-1d3a-43cb-be40-251135315841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First input with target = 1\n",
            "Old weight =  [ 1  1  1 -1  1 -1  1  1  1]\n",
            "Bias value =  1\n",
            "/n\n",
            "Second input with target = -1\n",
            "New weight =  [ 0  0  0 -2  2 -2  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To implement Kohonen Self-Organizing Maps\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "class KohonenSOM:\n",
        "  def __init__(self, x, y, input_len, learning_rate=0.5, radius=None,\n",
        "radius_decay=0.99, learning_rate_decay=0.99):\n",
        " \"\"\"\n",
        "Initialize the Self-Organizing Map (SOM).\n",
        "Parameters:\n",
        "x, y: Dimensions of the SOM grid.\n",
        "input_len: Length of the input vectors.\n",
        "learning_rate: Initial learning rate.\n",
        "radius: Initial neighborhood radius. If None, it will be set to\n",
        "\n",
        "max(x, y) / 2.\n",
        "\n",
        "radius_decay: Decay rate for the radius.\n",
        "learning_rate_decay: Decay rate for the learning rate.\n",
        "\"\"\"\n",
        "self.x = x\n",
        "self.y = y\n",
        "self.input_len = input_len\n",
        "self.learning_rate = learning_rate\n",
        "self.radius = radius if radius is not None else max(x, y) / 2\n",
        "self.radius_decay = radius_decay\n",
        "self.learning_rate_decay = learning_rate_decay\n",
        "# Initialize the weights randomly\n",
        "self.weights = np.random.rand(x, y, input_len)\n",
        "def train(self, data, num_iterations):\n",
        "\"\"\"\n",
        "Train the SOM with the given data.\n",
        "Parameters:\n",
        "data: The input data for training.\n",
        "num_iterations: Number of iterations for training.\n",
        "\"\"\"\n",
        "for i in range(num_iterations):\n",
        "# Select a random sample from the data\n",
        "sample = data[np.random.randint(len(data))]\n",
        "# Find the Best Matching Unit (BMU)\n",
        "bmu_index = self.find_bmu(sample)\n",
        "# Update the weights of the BMU and its neighbors\n",
        "self.update_weights(sample, bmu_index, i, num_iterations)\n",
        "\n",
        "# Decay the learning rate and radius\n",
        "self.learning_rate *= self.learning_rate_decay\n",
        "self.radius *= self.radius_decay\n",
        "\n",
        "def find_bmu(self, sample):\n",
        "\"\"\"\n",
        "Find the Best Matching Unit (BMU) for a given sample.\n",
        "Parameters:\n",
        "sample: The input sample vector.\n",
        "Returns:\n",
        "bmu_index: The index of the BMU in the SOM grid.\n",
        "\"\"\"\n",
        "distances = np.linalg.norm(self.weights - sample, axis=-1)\n",
        "bmu_index = np.unravel_index(np.argmin(distances), (self.x,\n",
        "self.y))\n",
        "\n",
        "return bmu_index\n",
        "def update_weights(self, sample, bmu_index, iteration,\n",
        "num_iterations):\n",
        "\"\"\"\n",
        "Update the weights of the BMU and its neighbors.\n",
        "Parameters:\n",
        "sample: The input sample vector.\n",
        "bmu_index: The index of the BMU in the SOM grid.\n",
        "iteration: The current iteration number.\n",
        "num_iterations: The total number of iterations.\n",
        "\"\"\"\n",
        "for i in range(self.x):\n",
        "for j in range(self.y):\n",
        "# Calculate the distance from the BMU\n",
        "distance_to_bmu = np.linalg.norm(np.array([i, j]) -\n",
        "\n",
        "np.array(bmu_index))\n",
        "\n",
        "# Calculate the neighborhood function\n",
        "if distance_to_bmu <= self.radius:\n",
        "influence = np.exp(-distance_to_bmu**2 / (2 *\n",
        "\n",
        "(self.radius**2)))\n",
        "\n",
        "# Update the weights\n",
        "self.weights[i, j, :] += influence *\n",
        "self.learning_rate * (sample - self.weights[i, j, :])\n",
        "def visualize(self):\n",
        "\"\"\"\n",
        "Visualize the SOM weights.\n",
        "\n",
        "\"\"\"\n",
        "plt.imshow(self.weights.reshape(self.x * self.y,\n",
        "self.input_len), cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "# Generate some random data\n",
        "data = np.random.rand(100, 3) # 100 samples, each with 3 features\n",
        "# Initialize the SOM\n",
        "som = KohonenSOM(x=10, y=10, input_len=3, learning_rate=0.5)\n",
        "# Train the SOM\n",
        "som.train(data, num_iterations=1000)\n",
        "# Visualize the SOM\n",
        "som.visualize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "0GxPKLiW_LdK",
        "outputId": "fe968145-305e-4ff9-956b-77ee2a41729d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Solve the Hamming Network, given the exemplar vectors.\n",
        "import numpy as np\n",
        "# Define the exemplar vectors (pre-defined inputs)\n",
        "exemplar_vectors = np.array([\n",
        "[1, 0, 1, 0, 1, 1, 0, 1],\n",
        "[0, 1, 0, 1, 0, 0, 1, 0],\n",
        "[1, 1, 1, 1, 0, 1, 0, 0]\n",
        "])\n",
        "# Define the input vector\n",
        "input_vector = np.array([1, 0, 1, 1, 0, 1, 0, 1])\n",
        "def hamming_distance(v1, v2):\n",
        "\"\"\"\n",
        "Compute the Hamming distance between two binary vectors.\n",
        "\"\"\"\n",
        "return np.sum(v1 != v2)\n",
        "def hamming_network(input_vector, exemplar_vectors):\n",
        "\"\"\"\n",
        "Find the exemplar vector with the smallest Hamming distance to the\n",
        "input vector.\n",
        "\"\"\"\n",
        "distances = np.array([hamming_distance(input_vector, ev) for ev in\n",
        "exemplar_vectors])\n",
        "min_distance_index = np.argmin(distances)\n",
        "return min_distance_index, distances[min_distance_index]\n",
        "# Run the Hamming Network\n",
        "index, distance = hamming_network(input_vector, exemplar_vectors)\n",
        "# Output the result\n",
        "print(f\"The input vector is closest to exemplar vector at index {index}\n",
        "with a Hamming distance of {distance}.\")"
      ],
      "metadata": {
        "id": "_LfqWO1EARQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a program for implementing BAM network.\n",
        "import numpy as np\n",
        "#Defining BAM class\n",
        "class BAM:\n",
        "def __init__(self):\n",
        "self.weights = None\n",
        "def train(self, patterns_A, patterns_B):\n",
        "# Initialize weights to zero\n",
        "num_features_A = patterns_A.shape[1]\n",
        "num_features_B = patterns_B.shape[1]\n",
        "self.weights = np.zeros((num_features_A, num_features_B))\n",
        "# Train weights using Hebbian learning rule\n",
        "for a, b in zip(patterns_A, patterns_B):\n",
        "self.weights += np.outer(a, b)\n",
        "\n",
        "def recall_A(self, pattern_B):\n",
        "# Recall pattern A given pattern B\n",
        "result = np.dot(pattern_B, self.weights.T)\n",
        "return np.sign(result)\n",
        "def recall_B(self, pattern_A):\n",
        "# Recall pattern B given pattern A\n",
        "result = np.dot(pattern_A, self.weights)\n",
        "return np.sign(result)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "# Define the training patterns\n",
        "patterns_A = np.array([[1, 1, -1], [-1, 1, 1], [-1, -1, -1]])\n",
        "\n",
        "patterns_B = np.array([[1, -1], [-1, 1], [1, 1]])\n",
        "# Initialize BAM\n",
        "bam = BAM()\n",
        "# Train BAM with the patterns\n",
        "bam.train(patterns_A, patterns_B)\n",
        "# Test recall for pattern B\n",
        "test_pattern_B = np.array([1, -1])\n",
        "recalled_pattern_A = bam.recall_A(test_pattern_B)\n",
        "print(\"Recalled Pattern A for test pattern B\", test_pattern_B,\n",
        "\"is:\", recalled_pattern_A)\n",
        "# Test recall for pattern A\n",
        "test_pattern_A = np.array([1, 1, -1])\n",
        "recalled_pattern_B = bam.recall_B(test_pattern_A)\n",
        "print(\"Recalled Pattern B for test pattern A\", test_pattern_A,\n",
        "\"is:\", recalled_pattern_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "0wz5njxKApRm",
        "outputId": "d3a7a347-005f-41b0-9ec0-573fdf31e519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after class definition on line 4 (<ipython-input-20-18d0b313a554>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-18d0b313a554>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    def __init__(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 4\n"
          ]
        }
      ]
    }
  ]
}